---
layout: post
title: "10 minutes to pandas（下）"
author: "L-Y-N"
categories: pandas
tags: [pandas]
image: 2018-02-02-10MinutesToPandas2.png
---

# 10 minutes to pandas（下）

---

## dataframe的融合操作

### 拼接concatenate

输入：

```python
df1 = pd.DataFrame(np.random.randn(5, 4))
df1
df2 = pd.DataFrame(np.random.randn(3, 4))
df2
df3 = pd.concat([df1,df2])
df3
```

输出：

```python
			0			1			2			3
0	0.052221	1.039633	-0.655808	-0.119177
1	0.294135	-0.698753	1.275731	0.653338
2	-1.237282	0.381286	-0.505146	-0.631613
3	-0.003601	0.222367	-0.585229	0.272045
4	0.616132	0.468298	-0.327995	0.759026


			0			1			2			3
0	0.543748	-1.225501	-0.561240	-0.300863
1	0.256646	0.314498	-0.617339	-0.460643
2	-0.811863	-1.542370	-0.455660	0.147871


			0			1			2			3
0	0.052221	1.039633	-0.655808	-0.119177
1	0.294135	-0.698753	1.275731	0.653338
2	-1.237282	0.381286	-0.505146	-0.631613
3	-0.003601	0.222367	-0.585229	0.272045
4	0.616132	0.468298	-0.327995	0.759026
0	0.543748	-1.225501	-0.561240	-0.300863
1	0.256646	0.314498	-0.617339	-0.460643
2	-0.811863	-1.542370	-0.455660	0.147871
```

**明显可见，concat将两个dataframe合并了起来，这在处理多个样本数据时，对数据的汇总时有大用处**

## Group by 按组划分

### groupby函数

先建立一个DF并输出：

```python
df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',
                           'foo', 'bar', 'foo', 'foo'],
                   'B' : ['one', 'one', 'two', 'three',
                         'two', 'two', 'one', 'three'],
                    'C' : np.random.randn(8),
                    'D' : np.random.randn(8)})
df
```

DF如下：

```python
 	 A      B         C         D
0  foo    one -1.202872 -0.055224
1  bar    one -1.814470  2.395985
2  foo    two  1.018601  1.552825
3  bar  three -0.595447  0.166599
4  foo    two  1.395433  0.047609
5  bar    two -0.392670 -0.136473
6  foo    one  0.007207 -0.561757
7  foo  three  1.928123 -1.623033
```

**groupby['A']**

```python
df.groupby('A').sum()
#按照df的Acolumns下的数据标签进行分组，这中间包含了一层取去重的操作
#并调用sum（）函数求和
```

结果：

```python
            C        D
A                     
bar -2.802588  2.42611
foo  3.146492 -0.63958
#可见左侧是A columns的两个bar和foo标签，右侧是求和后的数值
```

**groupby  A 和  B**

```python
df.groupby(['A','B']).sum()
```

结果：

```python
                  C         D
A   B                        
bar one   -1.814470  2.395985
    three -0.595447  0.166599
    two   -0.392670 -0.136473
foo one   -1.195665 -0.616981
    three  1.928123 -1.623033
    two    2.414034  1.600434
```

**明显的发现，在对A的bar和foo分组后，再进一步在B column中进行细分，并对其进行求和操作，则在对包含大量标签的数据，进行分组、细分时相当方便。**

## 数据透视表Pivot table

>A **\*pivot table*** is a table that summarizes data in another table, and is made by applying an operation such as sorting, averaging, or summing to data in the first table, typically including grouping of the data. 															---------------Wikipedia

输入：

```python
df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,
                    'B' : ['A', 'B', 'C'] * 4,
                    'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,
                    'D' : np.random.randn(12),
                    'E' : np.random.randn(12)})
df
```

输出：

```python
		A  B    C         D         E
0     one  A  foo  1.418757 -0.179666
1     one  B  foo -1.879024  1.291836
2     two  C  foo  0.536826 -0.009614
3   three  A  bar  1.006160  0.392149
4     one  B  bar -0.029716  0.264599
5     one  C  bar -1.146178 -0.057409
6     two  A  foo  0.100900 -1.425638
7   three  B  foo -1.035018  1.024098
8     one  C  foo  0.314665 -0.106062
9     one  A  bar -0.773723  1.824375
10    two  B  bar -1.170653  0.595974
11  three  C  bar  0.648740  1.167115
```

生成数据透视图：

```python
pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])
#可以看见数据源为df
#对D column的数据进行透视
#以C column的标签进行一级分类
#对A B column的标签进行二级分类
```

输出：

```python
C             bar       foo
A     B                    
one   A -0.773723  1.418757
      B -0.029716 -1.879024
      C -1.146178  0.314665
three A  1.006160       NaN
      B       NaN -1.035018
      C  0.648740       NaN
two   A       NaN  0.100900
      B -1.170653       NaN
      C       NaN  0.536826
```

可见数据透视图在处理带有大量标签的数据时，可以将对数据进行多标签的索引，这在处理具有多重属性的对象时非常方便。

## 时间序列

现实生活中，有相当多的数据分析是和时间相关的。pandas为我们提供了相当方便的时间序列工具，可以将各种数据转换为时间，并且在很多地方应用。

### 生成一个时间序列

输入：

```python
rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')
#用date_range函数生成一个时间序列，起点是3/6/2012 00:00
#生成5次
#每次间隔为  D     ,其中：S 代表seconds，M代表month，D代表days，W代表weekends
```

输出：

```python
DatetimeIndex(['2012-03-06', '2012-03-07', '2012-03-08', '2012-03-09',
               '2012-03-10'],
              dtype='datetime64[ns]', freq='D')
```

可见，将生成以天为间隔，容量为100个样本的一个时间序列。、

输入：

```python
ts = pd.Series(np.random.randn(len(rng)), rng)
ts
```

输出：

```python
2012-03-06    0.464000
2012-03-07    0.227371
2012-03-08   -0.496922
2012-03-09    0.306389
2012-03-10   -2.290613
Freq: D, dtype: float64
#可见这样以时间序列为index，生成了一个Series，DataFrame的生成也是类似的
```

## 获取数据I/O

### CSV文件

#### 读取CSV文件

输入：

```python
pd.read_csv('foo.csv')#用得非常频繁的read_csv()函数
```

输出：

```python
	Unnamed: 0          A          B         C          D
0    2000-01-01   0.266457  -0.399641 -0.219582   1.186860
1    2000-01-02  -1.170732  -0.345873  1.653061  -0.282953
2    2000-01-03  -1.734933   0.530468  2.060811  -0.515536
3    2000-01-04  -1.555121   1.452620  0.239859  -1.156896
4    2000-01-05   0.578117   0.511371  0.103552  -2.428202
5    2000-01-06   0.478344   0.449933 -0.741620  -1.962409
6    2000-01-07   1.235339  -0.091757 -1.543861  -1.084753
..          ...        ...        ...       ...        ...
993  2002-09-20 -10.628548  -9.153563 -7.883146  28.313940
994  2002-09-21 -10.390377  -8.727491 -6.399645  30.914107
995  2002-09-22  -8.985362  -8.485624 -4.669462  31.367740
996  2002-09-23  -9.558560  -8.781216 -4.499815  30.518439
997  2002-09-24  -9.902058  -9.340490 -4.386639  30.105593
998  2002-09-25 -10.216020  -9.480682 -3.933802  29.758560
999  2002-09-26 -11.856774 -10.671012 -3.216025  29.369368

[1000 rows x 5 columns]

```

**随即将一个CSV文件转化为了一个DataFrame。**

#### 写入CSV文件

```python
df.to_csv('foo.csv')
#to_csv()函数即可
```



### HDF5文件

暂时还未接触过，以后再更新。

### Excel文件

#### 读取Excel文件

输入：

```python
pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])
#读取sheet1的内容，NaN的值用NA代替
```

输出：

```python
 		 			A          B         C          D
2000-01-01   0.266457  -0.399641 -0.219582   1.186860
2000-01-02  -1.170732  -0.345873  1.653061  -0.282953
2000-01-03  -1.734933   0.530468  2.060811  -0.515536
2000-01-04  -1.555121   1.452620  0.239859  -1.156896
2000-01-05   0.578117   0.511371  0.103552  -2.428202
2000-01-06   0.478344   0.449933 -0.741620  -1.962409
2000-01-07   1.235339  -0.091757 -1.543861  -1.084753
...               ...        ...       ...        ...
2002-09-20 -10.628548  -9.153563 -7.883146  28.313940
2002-09-21 -10.390377  -8.727491 -6.399645  30.914107
2002-09-22  -8.985362  -8.485624 -4.669462  31.367740
2002-09-23  -9.558560  -8.781216 -4.499815  30.518439
2002-09-24  -9.902058  -9.340490 -4.386639  30.105593
2002-09-25 -10.216020  -9.480682 -3.933802  29.758560
2002-09-26 -11.856774 -10.671012 -3.216025  29.369368

[1000 rows x 4 columns]
```

#### 写入Excel文件

```python
df.to_excel('foo.xlsx', sheet_name='Sheet1')
```

即可将当前dataframe写入到foo.xlsx的sheet1中。












